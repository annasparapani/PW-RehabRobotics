{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'; \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn import metrics as skmetrics\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project folder\n",
    "BASE_DIR = os.getcwd()\n",
    "# Data folder\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "# Model folder\n",
    "MODEL_DIR = os.path.join(BASE_DIR, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155330</td>\n",
       "      <td>9.281200</td>\n",
       "      <td>2.855958</td>\n",
       "      <td>0.197017</td>\n",
       "      <td>0.242473</td>\n",
       "      <td>-0.105641</td>\n",
       "      <td>2.789788</td>\n",
       "      <td>1.701158</td>\n",
       "      <td>9.405596</td>\n",
       "      <td>-0.480803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244368</td>\n",
       "      <td>-0.006185</td>\n",
       "      <td>0.042704</td>\n",
       "      <td>2.085785</td>\n",
       "      <td>1.705704</td>\n",
       "      <td>10.557218</td>\n",
       "      <td>-0.009413</td>\n",
       "      <td>0.086448</td>\n",
       "      <td>-0.025667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533410</td>\n",
       "      <td>9.678888</td>\n",
       "      <td>3.406178</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.004816</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>3.500079</td>\n",
       "      <td>1.854339</td>\n",
       "      <td>9.178548</td>\n",
       "      <td>-0.152411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260247</td>\n",
       "      <td>-0.011533</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>2.014660</td>\n",
       "      <td>0.458138</td>\n",
       "      <td>9.918830</td>\n",
       "      <td>-0.094358</td>\n",
       "      <td>-0.151352</td>\n",
       "      <td>-0.045302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.622131</td>\n",
       "      <td>9.301626</td>\n",
       "      <td>3.283064</td>\n",
       "      <td>0.117537</td>\n",
       "      <td>-0.051471</td>\n",
       "      <td>0.033258</td>\n",
       "      <td>3.789793</td>\n",
       "      <td>2.133887</td>\n",
       "      <td>8.879432</td>\n",
       "      <td>-0.073444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448343</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>0.044709</td>\n",
       "      <td>2.182447</td>\n",
       "      <td>0.820618</td>\n",
       "      <td>9.754001</td>\n",
       "      <td>-0.043106</td>\n",
       "      <td>-0.075111</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.233142</td>\n",
       "      <td>9.290875</td>\n",
       "      <td>3.439288</td>\n",
       "      <td>0.102044</td>\n",
       "      <td>-0.013881</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>3.239987</td>\n",
       "      <td>2.175467</td>\n",
       "      <td>9.067300</td>\n",
       "      <td>-0.083780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387229</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>1.889427</td>\n",
       "      <td>1.089229</td>\n",
       "      <td>9.700936</td>\n",
       "      <td>-0.038585</td>\n",
       "      <td>-0.092326</td>\n",
       "      <td>0.012525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089970</td>\n",
       "      <td>9.364922</td>\n",
       "      <td>3.368469</td>\n",
       "      <td>0.129967</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>-0.030541</td>\n",
       "      <td>3.181964</td>\n",
       "      <td>2.234861</td>\n",
       "      <td>8.967263</td>\n",
       "      <td>-0.084834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.072977</td>\n",
       "      <td>0.042589</td>\n",
       "      <td>1.995755</td>\n",
       "      <td>1.262767</td>\n",
       "      <td>9.808022</td>\n",
       "      <td>-0.041103</td>\n",
       "      <td>-0.080061</td>\n",
       "      <td>0.023730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.155330  9.281200  2.855958  0.197017  0.242473 -0.105641  2.789788   \n",
       "1  0.533410  9.678888  3.406178  0.185582 -0.004816  0.001878  3.500079   \n",
       "2  0.622131  9.301626  3.283064  0.117537 -0.051471  0.033258  3.789793   \n",
       "3  0.233142  9.290875  3.439288  0.102044 -0.013881  0.005395  3.239987   \n",
       "4  0.089970  9.364922  3.368469  0.129967  0.041832 -0.030541  3.181964   \n",
       "\n",
       "         7         8         9   ...        15        16        17        18  \\\n",
       "0  1.701158  9.405596 -0.480803  ...  0.244368 -0.006185  0.042704  2.085785   \n",
       "1  1.854339  9.178548 -0.152411  ...  0.260247 -0.011533  0.046843  2.014660   \n",
       "2  2.133887  8.879432 -0.073444  ...  0.448343  0.014342  0.044709  2.182447   \n",
       "3  2.175467  9.067300 -0.083780  ...  0.387229  0.020255  0.051541  1.889427   \n",
       "4  2.234861  8.967263 -0.084834  ...  0.268282  0.072977  0.042589  1.995755   \n",
       "\n",
       "         19         20        21        22        23  24  \n",
       "0  1.705704  10.557218 -0.009413  0.086448 -0.025667   0  \n",
       "1  0.458138   9.918830 -0.094358 -0.151352 -0.045302   0  \n",
       "2  0.820618   9.754001 -0.043106 -0.075111 -0.013892   0  \n",
       "3  1.089229   9.700936 -0.038585 -0.092326  0.012525   0  \n",
       "4  1.262767   9.808022 -0.041103 -0.080061  0.023730   0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, \"data_entire_eachSub.csv\"), header=None)\n",
    "#df = pd.read_csv('data_train.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    *** Fixed parameters that are defined and should not be changed\n",
    "'''\n",
    "NUM_XSENS = 4\n",
    "INPUT_FEATURES = NUM_XSENS * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    *** Parameters that should be tuned to solve the challenge ***\n",
    "'''\n",
    "\n",
    "# Number of tasks to classify (according to your experimental acquisition protocol)\n",
    "N_CLASSES = 4 \n",
    "# Length of the time window\n",
    "WINDOW_LENGTH = 5\n",
    "# Stride length (i.e., overlap between adjacent windows)\n",
    "STRIDE_LENGTH = 1\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-3\n",
    "# Number of neurons for each LSTM layer\n",
    "neurons = [40, 20]\n",
    "# Dropout ratio for each LSTM layer \n",
    "dropouts = [0.15, 0.15]\n",
    "# Number of training epochs\n",
    "N_EPOCHS = 5\n",
    "# Batch size for training\n",
    "batch_size = 32\n",
    "\n",
    "# Please provide a dropout value for each LSTM layer\n",
    "# Set dropout[i] = 0.0 to keep all connections\n",
    "assert(len(neurons) == len(dropouts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (X): (84363, 24) --- Output shape (y): (84363, 4)\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "X = df.iloc[:,0:-1].to_numpy()\n",
    "y = df.iloc[:,-1].to_numpy()\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "print(\"Input shape (X): {} --- Output shape (y): {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences(df, y, window_length, input_features, stride):\n",
    "    # Sanity check to avoid runtime errors\n",
    "    assert window_length % stride == 0\n",
    "    dataset = []; labels = []\n",
    "    # Take only meaningful features\n",
    "    if type(df) == pd.core.frame.DataFrame:\n",
    "        temp = df.copy().values\n",
    "    else:\n",
    "        temp = df\n",
    "    # Compute padding length\n",
    "    padding_len = window_length - len(temp)%window_length\n",
    "    # Create padding and concatenate it\n",
    "    padding = np.zeros((padding_len, input_features), dtype='float64')\n",
    "    temp = np.concatenate((temp,padding))\n",
    "    # Build features windows with their corresponding labels\n",
    "    idx = 0\n",
    "    while idx+window_length <= len(temp):\n",
    "        dataset.append(temp[idx:idx+window_length])\n",
    "        labels.append(y[idx])\n",
    "        idx += stride\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sets shape: (67490, 24) (67490, 4)\n",
      "Train sets shape: (16873, 24) (16873, 4)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    NOTE: in this example, we open a single file and we apply the train_test_split function\n",
    "          to extract 80% for training and 20% for testing the model.\n",
    "          In your code, you will need to load 2 files, 1 for training and 1 for testing\n",
    "'''\n",
    "\n",
    "# Use stratify=y to stratify on y (target variable)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "print(\"Train sets shape: {} {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Train sets shape: {} {}\".format(X_test.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and trasnform with scaler\n",
    "scaler = sklearn.preprocessing.MinMaxScaler((-1,1))\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale input (X) data \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 67490 is out of bounds for axis 0 with size 67490",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Convert to sequences of length WINDOW_LENGTH\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train, y_train \u001b[39m=\u001b[39m build_sequences(X_train, y_train, window_length\u001b[39m=\u001b[39;49mWINDOW_LENGTH, input_features\u001b[39m=\u001b[39;49mINPUT_FEATURES, stride\u001b[39m=\u001b[39;49mSTRIDE_LENGTH)\n\u001b[1;32m      3\u001b[0m X_test, y_test \u001b[39m=\u001b[39m build_sequences(X_test, y_test, window_length\u001b[39m=\u001b[39mWINDOW_LENGTH, input_features\u001b[39m=\u001b[39mINPUT_FEATURES, stride\u001b[39m=\u001b[39mSTRIDE_LENGTH)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain sets shape: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(X_train\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape))\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mbuild_sequences\u001b[0;34m(df, y, window_length, input_features, stride)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mwhile\u001b[39;00m idx\u001b[39m+\u001b[39mwindow_length \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(temp):\n\u001b[1;32m     18\u001b[0m     dataset\u001b[39m.\u001b[39mappend(temp[idx:idx\u001b[39m+\u001b[39mwindow_length])\n\u001b[0;32m---> 19\u001b[0m     labels\u001b[39m.\u001b[39mappend(y[idx])\n\u001b[1;32m     20\u001b[0m     idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m stride\n\u001b[1;32m     21\u001b[0m dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(dataset)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 67490 is out of bounds for axis 0 with size 67490"
     ]
    }
   ],
   "source": [
    "# Convert to sequences of length WINDOW_LENGTH\n",
    "X_train, y_train = build_sequences(X_train, y_train, window_length=WINDOW_LENGTH, input_features=INPUT_FEATURES, stride=STRIDE_LENGTH)\n",
    "X_test, y_test = build_sequences(X_test, y_test, window_length=WINDOW_LENGTH, input_features=INPUT_FEATURES, stride=STRIDE_LENGTH)\n",
    "\n",
    "print(\"Train sets shape: {} {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Train sets shape: {} {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model \n",
    "def lstm_model(neurons=neurons, dropouts=dropouts, learning_rate=learning_rate, output_classes=N_CLASSES, window=WINDOW_LENGTH, features=INPUT_FEATURES):\n",
    "    # Input layer\n",
    "    input_layer = tf.keras.layers.Input((window, features))\n",
    "    x = input_layer\n",
    "    # Build the model recursively based on the list of neurons for each LSTM cell\n",
    "    # Add a dropout layer after every LSTM layer\n",
    "    for i in range(len(neurons)):\n",
    "        y = tf.keras.layers.LSTM(neurons[i], activation = \"tanh\", return_sequences = not(i == len(neurons)-1), kernel_initializer = \"HeUniform\")(x)\n",
    "        y = tf.keras.layers.Dropout(dropouts[i])(y)\n",
    "        x = y\n",
    "    # Output layer with N_CLASSES neurons: each provides the probability that the input belongs to that class (their sum equals 1)\n",
    "    output_layer = tf.keras.layers.Dense(output_classes, activation='softmax', kernel_initializer=\"RandomNormal\", name='output_layer')(x)\n",
    "    # Build the model\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='task-classifier')\n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    # Compile and return the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"task-classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 24)]           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 5, 40)             10400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 40)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                4880      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 4)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,364\n",
      "Trainable params: 15,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM model and print its structure\n",
    "model = lstm_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 404952 into shape (5,24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fit with train data (NOTE: early stopping is active)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Read more here: https://keras.io/api/callbacks/early_stopping/\u001b[39;00m\n\u001b[1;32m      3\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, WINDOW_LENGTH, INPUT_FEATURES), y_train, \n\u001b[1;32m      4\u001b[0m           epochs\u001b[39m=\u001b[39mN_EPOCHS,\n\u001b[1;32m      5\u001b[0m           batch_size\u001b[39m=\u001b[39mbatch_size, \n\u001b[0;32m----> 6\u001b[0m           validation_data\u001b[39m=\u001b[39m(X_test\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, WINDOW_LENGTH, INPUT_FEATURES), y_test),\n\u001b[1;32m      7\u001b[0m           callbacks\u001b[39m=\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 404952 into shape (5,24)"
     ]
    }
   ],
   "source": [
    "# Fit with train data (NOTE: early stopping is active)\n",
    "# Read more here: https://keras.io/api/callbacks/early_stopping/\n",
    "history = model.fit(X_train.reshape(-1, WINDOW_LENGTH, INPUT_FEATURES), y_train, \n",
    "          epochs=N_EPOCHS,\n",
    "          batch_size=batch_size, \n",
    "          validation_data=(X_test.reshape(-1, WINDOW_LENGTH, INPUT_FEATURES), y_test),\n",
    "          callbacks=EarlyStopping(monitor='val_loss', patience=8, mode='min', restore_best_weights=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history (loss and accuracy)\n",
    "epochs = range(1, N_EPOCHS+1)\n",
    "\n",
    "plt.plot(epochs, history.history['accuracy'], 'bo', label='Training acc')\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, history.history['loss'], 'bo', label='Training loss')\n",
    "plt.plot(epochs, history.history['val_loss'], 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "y_pred = model.predict(X_test.reshape(-1, WINDOW_LENGTH, INPUT_FEATURES), \n",
    "                       batch_size=1,   # predict with batch_size = 1 for real-time use                \n",
    ")\n",
    "y_pred = np.argmax(y_pred, axis=-1) # Convert to Nx1 array\n",
    "y_test = np.argmax(y_test, axis=-1)\n",
    "\n",
    "print(\"Test accuracy: {:4.2f} %\".format(100*skmetrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for real-time use\n",
    "try:\n",
    "    os.makedirs(MODEL_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "try:\n",
    "    os.makedirs(MODEL_DIR)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "model.save(os.path.join(MODEL_DIR, \"{}.h5\".format(model.name)))\n",
    "with open(os.path.join(MODEL_DIR, \"{}_scaler.h5\".format(model.name)), 'wb') as f:\n",
    "    pickle.dump(scaler,f)\n",
    "\n",
    "print(\"Model exported to {}\".format(MODEL_DIR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "450022d656ba3f1bae49db00a35c39520a847981960e90b9743b5293af547c64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
